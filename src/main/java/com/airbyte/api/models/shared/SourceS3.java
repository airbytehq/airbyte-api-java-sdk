/* 
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */
package com.airbyte.api.models.shared;

import com.airbyte.api.utils.LazySingletonValue;
import com.airbyte.api.utils.Utils;
import com.fasterxml.jackson.annotation.JsonCreator;
import com.fasterxml.jackson.annotation.JsonIgnore;
import com.fasterxml.jackson.annotation.JsonInclude.Include;
import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.core.type.TypeReference;
import java.lang.Override;
import java.lang.String;
import java.lang.SuppressWarnings;
import java.time.OffsetDateTime;
import java.util.List;
import java.util.Objects;
import java.util.Optional;

/**
 * SourceS3
 * 
 * <p>NOTE: When this Spec is changed, legacy_config_transformer.py must also be modified to uptake the changes
 * because it is responsible for converting legacy S3 v3 configs into v4 configs using the File-Based CDK.
 */
public class SourceS3 {

    /**
     * In order to access private Buckets stored on AWS S3, this connector requires credentials with the proper permissions. If accessing publicly available data, this field is not necessary.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("aws_access_key_id")
    private Optional<String> awsAccessKeyId;

    /**
     * In order to access private Buckets stored on AWS S3, this connector requires credentials with the proper permissions. If accessing publicly available data, this field is not necessary.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("aws_secret_access_key")
    private Optional<String> awsSecretAccessKey;

    /**
     * Name of the S3 bucket where the file(s) exist.
     */
    @JsonProperty("bucket")
    private String bucket;

    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("delivery_method")
    private Optional<? extends SourceS3DeliveryMethod> deliveryMethod;

    /**
     * Endpoint to an S3 compatible service. Leave empty to use AWS.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("endpoint")
    private Optional<String> endpoint;

    /**
     * AWS region where the S3 bucket is located. If not provided, the region will be determined automatically.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("region_name")
    private Optional<String> regionName;

    /**
     * Specifies the Amazon Resource Name (ARN) of an IAM role that you want to use to perform operations requested using this profile. Set the External ID to the Airbyte workspace ID, which can be found in the URL of this page.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("role_arn")
    private Optional<String> roleArn;

    @JsonProperty("sourceType")
    private SourceS3S3 sourceType;

    /**
     * UTC date and time in the format 2017-01-25T00:00:00.000000Z. Any file modified before this date will not be replicated.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("start_date")
    private Optional<OffsetDateTime> startDate;

    /**
     * Each instance of this configuration defines a &lt;a href="https://docs.airbyte.com/cloud/core-concepts#stream"&gt;stream&lt;/a&gt;. Use this to define which files belong in the stream, their format, and how they should be parsed and validated. When sending data to warehouse destination such as Snowflake or BigQuery, each stream is a separate table.
     */
    @JsonProperty("streams")
    private List<SourceS3FileBasedStreamConfig> streams;

    @JsonCreator
    public SourceS3(
            @JsonProperty("aws_access_key_id") Optional<String> awsAccessKeyId,
            @JsonProperty("aws_secret_access_key") Optional<String> awsSecretAccessKey,
            @JsonProperty("bucket") String bucket,
            @JsonProperty("delivery_method") Optional<? extends SourceS3DeliveryMethod> deliveryMethod,
            @JsonProperty("endpoint") Optional<String> endpoint,
            @JsonProperty("region_name") Optional<String> regionName,
            @JsonProperty("role_arn") Optional<String> roleArn,
            @JsonProperty("start_date") Optional<OffsetDateTime> startDate,
            @JsonProperty("streams") List<SourceS3FileBasedStreamConfig> streams) {
        Utils.checkNotNull(awsAccessKeyId, "awsAccessKeyId");
        Utils.checkNotNull(awsSecretAccessKey, "awsSecretAccessKey");
        Utils.checkNotNull(bucket, "bucket");
        Utils.checkNotNull(deliveryMethod, "deliveryMethod");
        Utils.checkNotNull(endpoint, "endpoint");
        Utils.checkNotNull(regionName, "regionName");
        Utils.checkNotNull(roleArn, "roleArn");
        Utils.checkNotNull(startDate, "startDate");
        Utils.checkNotNull(streams, "streams");
        this.awsAccessKeyId = awsAccessKeyId;
        this.awsSecretAccessKey = awsSecretAccessKey;
        this.bucket = bucket;
        this.deliveryMethod = deliveryMethod;
        this.endpoint = endpoint;
        this.regionName = regionName;
        this.roleArn = roleArn;
        this.sourceType = Builder._SINGLETON_VALUE_SourceType.value();
        this.startDate = startDate;
        this.streams = streams;
    }
    
    public SourceS3(
            String bucket,
            List<SourceS3FileBasedStreamConfig> streams) {
        this(Optional.empty(), Optional.empty(), bucket, Optional.empty(), Optional.empty(), Optional.empty(), Optional.empty(), Optional.empty(), streams);
    }

    /**
     * In order to access private Buckets stored on AWS S3, this connector requires credentials with the proper permissions. If accessing publicly available data, this field is not necessary.
     */
    @JsonIgnore
    public Optional<String> awsAccessKeyId() {
        return awsAccessKeyId;
    }

    /**
     * In order to access private Buckets stored on AWS S3, this connector requires credentials with the proper permissions. If accessing publicly available data, this field is not necessary.
     */
    @JsonIgnore
    public Optional<String> awsSecretAccessKey() {
        return awsSecretAccessKey;
    }

    /**
     * Name of the S3 bucket where the file(s) exist.
     */
    @JsonIgnore
    public String bucket() {
        return bucket;
    }

    @SuppressWarnings("unchecked")
    @JsonIgnore
    public Optional<SourceS3DeliveryMethod> deliveryMethod() {
        return (Optional<SourceS3DeliveryMethod>) deliveryMethod;
    }

    /**
     * Endpoint to an S3 compatible service. Leave empty to use AWS.
     */
    @JsonIgnore
    public Optional<String> endpoint() {
        return endpoint;
    }

    /**
     * AWS region where the S3 bucket is located. If not provided, the region will be determined automatically.
     */
    @JsonIgnore
    public Optional<String> regionName() {
        return regionName;
    }

    /**
     * Specifies the Amazon Resource Name (ARN) of an IAM role that you want to use to perform operations requested using this profile. Set the External ID to the Airbyte workspace ID, which can be found in the URL of this page.
     */
    @JsonIgnore
    public Optional<String> roleArn() {
        return roleArn;
    }

    @JsonIgnore
    public SourceS3S3 sourceType() {
        return sourceType;
    }

    /**
     * UTC date and time in the format 2017-01-25T00:00:00.000000Z. Any file modified before this date will not be replicated.
     */
    @JsonIgnore
    public Optional<OffsetDateTime> startDate() {
        return startDate;
    }

    /**
     * Each instance of this configuration defines a &lt;a href="https://docs.airbyte.com/cloud/core-concepts#stream"&gt;stream&lt;/a&gt;. Use this to define which files belong in the stream, their format, and how they should be parsed and validated. When sending data to warehouse destination such as Snowflake or BigQuery, each stream is a separate table.
     */
    @JsonIgnore
    public List<SourceS3FileBasedStreamConfig> streams() {
        return streams;
    }

    public final static Builder builder() {
        return new Builder();
    }    

    /**
     * In order to access private Buckets stored on AWS S3, this connector requires credentials with the proper permissions. If accessing publicly available data, this field is not necessary.
     */
    public SourceS3 withAwsAccessKeyId(String awsAccessKeyId) {
        Utils.checkNotNull(awsAccessKeyId, "awsAccessKeyId");
        this.awsAccessKeyId = Optional.ofNullable(awsAccessKeyId);
        return this;
    }

    /**
     * In order to access private Buckets stored on AWS S3, this connector requires credentials with the proper permissions. If accessing publicly available data, this field is not necessary.
     */
    public SourceS3 withAwsAccessKeyId(Optional<String> awsAccessKeyId) {
        Utils.checkNotNull(awsAccessKeyId, "awsAccessKeyId");
        this.awsAccessKeyId = awsAccessKeyId;
        return this;
    }

    /**
     * In order to access private Buckets stored on AWS S3, this connector requires credentials with the proper permissions. If accessing publicly available data, this field is not necessary.
     */
    public SourceS3 withAwsSecretAccessKey(String awsSecretAccessKey) {
        Utils.checkNotNull(awsSecretAccessKey, "awsSecretAccessKey");
        this.awsSecretAccessKey = Optional.ofNullable(awsSecretAccessKey);
        return this;
    }

    /**
     * In order to access private Buckets stored on AWS S3, this connector requires credentials with the proper permissions. If accessing publicly available data, this field is not necessary.
     */
    public SourceS3 withAwsSecretAccessKey(Optional<String> awsSecretAccessKey) {
        Utils.checkNotNull(awsSecretAccessKey, "awsSecretAccessKey");
        this.awsSecretAccessKey = awsSecretAccessKey;
        return this;
    }

    /**
     * Name of the S3 bucket where the file(s) exist.
     */
    public SourceS3 withBucket(String bucket) {
        Utils.checkNotNull(bucket, "bucket");
        this.bucket = bucket;
        return this;
    }

    public SourceS3 withDeliveryMethod(SourceS3DeliveryMethod deliveryMethod) {
        Utils.checkNotNull(deliveryMethod, "deliveryMethod");
        this.deliveryMethod = Optional.ofNullable(deliveryMethod);
        return this;
    }

    public SourceS3 withDeliveryMethod(Optional<? extends SourceS3DeliveryMethod> deliveryMethod) {
        Utils.checkNotNull(deliveryMethod, "deliveryMethod");
        this.deliveryMethod = deliveryMethod;
        return this;
    }

    /**
     * Endpoint to an S3 compatible service. Leave empty to use AWS.
     */
    public SourceS3 withEndpoint(String endpoint) {
        Utils.checkNotNull(endpoint, "endpoint");
        this.endpoint = Optional.ofNullable(endpoint);
        return this;
    }

    /**
     * Endpoint to an S3 compatible service. Leave empty to use AWS.
     */
    public SourceS3 withEndpoint(Optional<String> endpoint) {
        Utils.checkNotNull(endpoint, "endpoint");
        this.endpoint = endpoint;
        return this;
    }

    /**
     * AWS region where the S3 bucket is located. If not provided, the region will be determined automatically.
     */
    public SourceS3 withRegionName(String regionName) {
        Utils.checkNotNull(regionName, "regionName");
        this.regionName = Optional.ofNullable(regionName);
        return this;
    }

    /**
     * AWS region where the S3 bucket is located. If not provided, the region will be determined automatically.
     */
    public SourceS3 withRegionName(Optional<String> regionName) {
        Utils.checkNotNull(regionName, "regionName");
        this.regionName = regionName;
        return this;
    }

    /**
     * Specifies the Amazon Resource Name (ARN) of an IAM role that you want to use to perform operations requested using this profile. Set the External ID to the Airbyte workspace ID, which can be found in the URL of this page.
     */
    public SourceS3 withRoleArn(String roleArn) {
        Utils.checkNotNull(roleArn, "roleArn");
        this.roleArn = Optional.ofNullable(roleArn);
        return this;
    }

    /**
     * Specifies the Amazon Resource Name (ARN) of an IAM role that you want to use to perform operations requested using this profile. Set the External ID to the Airbyte workspace ID, which can be found in the URL of this page.
     */
    public SourceS3 withRoleArn(Optional<String> roleArn) {
        Utils.checkNotNull(roleArn, "roleArn");
        this.roleArn = roleArn;
        return this;
    }

    /**
     * UTC date and time in the format 2017-01-25T00:00:00.000000Z. Any file modified before this date will not be replicated.
     */
    public SourceS3 withStartDate(OffsetDateTime startDate) {
        Utils.checkNotNull(startDate, "startDate");
        this.startDate = Optional.ofNullable(startDate);
        return this;
    }

    /**
     * UTC date and time in the format 2017-01-25T00:00:00.000000Z. Any file modified before this date will not be replicated.
     */
    public SourceS3 withStartDate(Optional<OffsetDateTime> startDate) {
        Utils.checkNotNull(startDate, "startDate");
        this.startDate = startDate;
        return this;
    }

    /**
     * Each instance of this configuration defines a &lt;a href="https://docs.airbyte.com/cloud/core-concepts#stream"&gt;stream&lt;/a&gt;. Use this to define which files belong in the stream, their format, and how they should be parsed and validated. When sending data to warehouse destination such as Snowflake or BigQuery, each stream is a separate table.
     */
    public SourceS3 withStreams(List<SourceS3FileBasedStreamConfig> streams) {
        Utils.checkNotNull(streams, "streams");
        this.streams = streams;
        return this;
    }

    
    @Override
    public boolean equals(java.lang.Object o) {
        if (this == o) {
            return true;
        }
        if (o == null || getClass() != o.getClass()) {
            return false;
        }
        SourceS3 other = (SourceS3) o;
        return 
            Objects.deepEquals(this.awsAccessKeyId, other.awsAccessKeyId) &&
            Objects.deepEquals(this.awsSecretAccessKey, other.awsSecretAccessKey) &&
            Objects.deepEquals(this.bucket, other.bucket) &&
            Objects.deepEquals(this.deliveryMethod, other.deliveryMethod) &&
            Objects.deepEquals(this.endpoint, other.endpoint) &&
            Objects.deepEquals(this.regionName, other.regionName) &&
            Objects.deepEquals(this.roleArn, other.roleArn) &&
            Objects.deepEquals(this.sourceType, other.sourceType) &&
            Objects.deepEquals(this.startDate, other.startDate) &&
            Objects.deepEquals(this.streams, other.streams);
    }
    
    @Override
    public int hashCode() {
        return Objects.hash(
            awsAccessKeyId,
            awsSecretAccessKey,
            bucket,
            deliveryMethod,
            endpoint,
            regionName,
            roleArn,
            sourceType,
            startDate,
            streams);
    }
    
    @Override
    public String toString() {
        return Utils.toString(SourceS3.class,
                "awsAccessKeyId", awsAccessKeyId,
                "awsSecretAccessKey", awsSecretAccessKey,
                "bucket", bucket,
                "deliveryMethod", deliveryMethod,
                "endpoint", endpoint,
                "regionName", regionName,
                "roleArn", roleArn,
                "sourceType", sourceType,
                "startDate", startDate,
                "streams", streams);
    }
    
    public final static class Builder {
 
        private Optional<String> awsAccessKeyId = Optional.empty();
 
        private Optional<String> awsSecretAccessKey = Optional.empty();
 
        private String bucket;
 
        private Optional<? extends SourceS3DeliveryMethod> deliveryMethod = Optional.empty();
 
        private Optional<String> endpoint;
 
        private Optional<String> regionName = Optional.empty();
 
        private Optional<String> roleArn = Optional.empty();
 
        private Optional<OffsetDateTime> startDate = Optional.empty();
 
        private List<SourceS3FileBasedStreamConfig> streams;
        
        private Builder() {
          // force use of static builder() method
        }

        /**
         * In order to access private Buckets stored on AWS S3, this connector requires credentials with the proper permissions. If accessing publicly available data, this field is not necessary.
         */
        public Builder awsAccessKeyId(String awsAccessKeyId) {
            Utils.checkNotNull(awsAccessKeyId, "awsAccessKeyId");
            this.awsAccessKeyId = Optional.ofNullable(awsAccessKeyId);
            return this;
        }

        /**
         * In order to access private Buckets stored on AWS S3, this connector requires credentials with the proper permissions. If accessing publicly available data, this field is not necessary.
         */
        public Builder awsAccessKeyId(Optional<String> awsAccessKeyId) {
            Utils.checkNotNull(awsAccessKeyId, "awsAccessKeyId");
            this.awsAccessKeyId = awsAccessKeyId;
            return this;
        }

        /**
         * In order to access private Buckets stored on AWS S3, this connector requires credentials with the proper permissions. If accessing publicly available data, this field is not necessary.
         */
        public Builder awsSecretAccessKey(String awsSecretAccessKey) {
            Utils.checkNotNull(awsSecretAccessKey, "awsSecretAccessKey");
            this.awsSecretAccessKey = Optional.ofNullable(awsSecretAccessKey);
            return this;
        }

        /**
         * In order to access private Buckets stored on AWS S3, this connector requires credentials with the proper permissions. If accessing publicly available data, this field is not necessary.
         */
        public Builder awsSecretAccessKey(Optional<String> awsSecretAccessKey) {
            Utils.checkNotNull(awsSecretAccessKey, "awsSecretAccessKey");
            this.awsSecretAccessKey = awsSecretAccessKey;
            return this;
        }

        /**
         * Name of the S3 bucket where the file(s) exist.
         */
        public Builder bucket(String bucket) {
            Utils.checkNotNull(bucket, "bucket");
            this.bucket = bucket;
            return this;
        }

        public Builder deliveryMethod(SourceS3DeliveryMethod deliveryMethod) {
            Utils.checkNotNull(deliveryMethod, "deliveryMethod");
            this.deliveryMethod = Optional.ofNullable(deliveryMethod);
            return this;
        }

        public Builder deliveryMethod(Optional<? extends SourceS3DeliveryMethod> deliveryMethod) {
            Utils.checkNotNull(deliveryMethod, "deliveryMethod");
            this.deliveryMethod = deliveryMethod;
            return this;
        }

        /**
         * Endpoint to an S3 compatible service. Leave empty to use AWS.
         */
        public Builder endpoint(String endpoint) {
            Utils.checkNotNull(endpoint, "endpoint");
            this.endpoint = Optional.ofNullable(endpoint);
            return this;
        }

        /**
         * Endpoint to an S3 compatible service. Leave empty to use AWS.
         */
        public Builder endpoint(Optional<String> endpoint) {
            Utils.checkNotNull(endpoint, "endpoint");
            this.endpoint = endpoint;
            return this;
        }

        /**
         * AWS region where the S3 bucket is located. If not provided, the region will be determined automatically.
         */
        public Builder regionName(String regionName) {
            Utils.checkNotNull(regionName, "regionName");
            this.regionName = Optional.ofNullable(regionName);
            return this;
        }

        /**
         * AWS region where the S3 bucket is located. If not provided, the region will be determined automatically.
         */
        public Builder regionName(Optional<String> regionName) {
            Utils.checkNotNull(regionName, "regionName");
            this.regionName = regionName;
            return this;
        }

        /**
         * Specifies the Amazon Resource Name (ARN) of an IAM role that you want to use to perform operations requested using this profile. Set the External ID to the Airbyte workspace ID, which can be found in the URL of this page.
         */
        public Builder roleArn(String roleArn) {
            Utils.checkNotNull(roleArn, "roleArn");
            this.roleArn = Optional.ofNullable(roleArn);
            return this;
        }

        /**
         * Specifies the Amazon Resource Name (ARN) of an IAM role that you want to use to perform operations requested using this profile. Set the External ID to the Airbyte workspace ID, which can be found in the URL of this page.
         */
        public Builder roleArn(Optional<String> roleArn) {
            Utils.checkNotNull(roleArn, "roleArn");
            this.roleArn = roleArn;
            return this;
        }

        /**
         * UTC date and time in the format 2017-01-25T00:00:00.000000Z. Any file modified before this date will not be replicated.
         */
        public Builder startDate(OffsetDateTime startDate) {
            Utils.checkNotNull(startDate, "startDate");
            this.startDate = Optional.ofNullable(startDate);
            return this;
        }

        /**
         * UTC date and time in the format 2017-01-25T00:00:00.000000Z. Any file modified before this date will not be replicated.
         */
        public Builder startDate(Optional<OffsetDateTime> startDate) {
            Utils.checkNotNull(startDate, "startDate");
            this.startDate = startDate;
            return this;
        }

        /**
         * Each instance of this configuration defines a &lt;a href="https://docs.airbyte.com/cloud/core-concepts#stream"&gt;stream&lt;/a&gt;. Use this to define which files belong in the stream, their format, and how they should be parsed and validated. When sending data to warehouse destination such as Snowflake or BigQuery, each stream is a separate table.
         */
        public Builder streams(List<SourceS3FileBasedStreamConfig> streams) {
            Utils.checkNotNull(streams, "streams");
            this.streams = streams;
            return this;
        }
        
        public SourceS3 build() {
            if (endpoint == null) {
                endpoint = _SINGLETON_VALUE_Endpoint.value();
            }
            return new SourceS3(
                awsAccessKeyId,
                awsSecretAccessKey,
                bucket,
                deliveryMethod,
                endpoint,
                regionName,
                roleArn,
                startDate,
                streams);
        }

        private static final LazySingletonValue<Optional<String>> _SINGLETON_VALUE_Endpoint =
                new LazySingletonValue<>(
                        "endpoint",
                        "\"\"",
                        new TypeReference<Optional<String>>() {});

        private static final LazySingletonValue<SourceS3S3> _SINGLETON_VALUE_SourceType =
                new LazySingletonValue<>(
                        "sourceType",
                        "\"s3\"",
                        new TypeReference<SourceS3S3>() {});
    }
}
